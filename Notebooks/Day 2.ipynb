{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "555580ca",
   "metadata": {},
   "source": [
    "# DAY 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925c8488",
   "metadata": {},
   "source": [
    "## Import the Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f3ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "from scipy.signal import resample\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.python.solutions.drawing_utils import draw_landmarks\n",
    "from mediapipe.python.solutions.drawing_styles import get_default_pose_landmarks_style\n",
    "\n",
    "import yt_dlp\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "from scipy.spatial.distance import euclidean\n",
    "from dtaidistance import dtw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0ed0889",
   "metadata": {},
   "source": [
    "## 1.Keypoint Extrations from the video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f296ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keypoints_from_video(video_path, output_csv, max_frames=None, start_sec=None, end_sec=None, debug_dir=None):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    mp_pose = mp.solutions.pose\n",
    "    pose = mp_pose.Pose()\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    duration = total_frames / fps\n",
    "\n",
    "    print(f\"\\n[INFO] Processing video: {video_path}\")\n",
    "    print(f\"[INFO] FPS: {fps:.2f}, Total Frames: {int(total_frames)}, Duration: {duration:.2f}s\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)\n",
    "    if debug_dir:\n",
    "        os.makedirs(debug_dir, exist_ok=True)\n",
    "\n",
    "    frame_idx = 0\n",
    "    saved_idx = 0\n",
    "    first_frame_time, last_frame_time = None, None\n",
    "\n",
    "    with open(output_csv, mode='w', newline='') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        header = ['frame']\n",
    "        for i in range(33):\n",
    "            header += [f'x{i}', f'y{i}', f'z{i}']\n",
    "        writer.writerow(header)\n",
    "\n",
    "        while cap.isOpened():\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "\n",
    "            time_sec = frame_idx / fps\n",
    "            frame_idx += 1\n",
    "\n",
    "            if start_sec and time_sec < start_sec:\n",
    "                continue\n",
    "            if end_sec and time_sec > end_sec:\n",
    "                break\n",
    "            if max_frames and saved_idx >= max_frames:\n",
    "                break\n",
    "\n",
    "            if first_frame_time is None:\n",
    "                first_frame_time = time_sec\n",
    "            last_frame_time = time_sec\n",
    "\n",
    "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            result = pose.process(frame_rgb)\n",
    "\n",
    "            row = [saved_idx]\n",
    "            if result.pose_landmarks:\n",
    "                for lm in result.pose_landmarks.landmark:\n",
    "                    row += [lm.x, lm.y, lm.z]\n",
    "            else:\n",
    "                row += [0.0] * (33 * 3)\n",
    "            writer.writerow(row)\n",
    "\n",
    "            if debug_dir and saved_idx % 30 == 0:\n",
    "                debug_frame = frame.copy()\n",
    "                if result.pose_landmarks:\n",
    "                    draw_landmarks(\n",
    "                        debug_frame,\n",
    "                        result.pose_landmarks,\n",
    "                        mp_pose.POSE_CONNECTIONS,\n",
    "                        landmark_drawing_spec=get_default_pose_landmarks_style()\n",
    "                    )\n",
    "                debug_path = os.path.join(debug_dir, f\"frame_{saved_idx}_pose.jpg\")\n",
    "                cv2.imwrite(debug_path, debug_frame)\n",
    "\n",
    "            saved_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    print(f\"[INFO] Keypoints saved to {output_csv}\")\n",
    "    print(f\"[INFO] Frames processed: {saved_idx}\")\n",
    "    print(f\"[INFO] Time range: {first_frame_time:.2f}s to {last_frame_time:.2f}s\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2596fd82",
   "metadata": {},
   "source": [
    "## 2. DTW Score Comparison "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598d4a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoints_from_csv(csv_file):\n",
    "    keypoints = []\n",
    "    with open(csv_file, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            frame_data = list(map(float, row[1:]))\n",
    "            keypoints.append(frame_data)\n",
    "    return np.array(keypoints)\n",
    "\n",
    "\n",
    "def compute_dtw_distance(seq1, seq2):\n",
    "    distance, path = fastdtw(seq1, seq2, dist=euclidean)\n",
    "    return distance, path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97de12ea",
   "metadata": {},
   "source": [
    "## 3. Preprocess Keypoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_keypoints(csv_path, selected_indices):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    sequence = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        keypoints = np.array(row[1:]).astype(float) \n",
    "        pose = []\n",
    "        for i in selected_indices:\n",
    "            x, y = keypoints[i*3], keypoints[i*3 + 1]  \n",
    "            pose.extend([x, y])\n",
    "        pose = np.array(pose)\n",
    "\n",
    "        root_x, root_y = pose[0], pose[1]\n",
    "        pose -= np.array([root_x, root_y] * (len(pose) // 2))\n",
    "        norm = np.linalg.norm(pose)\n",
    "        pose = pose / norm if norm != 0 else pose\n",
    "\n",
    "        sequence.append(pose)\n",
    "    \n",
    "    return np.array(sequence)\n",
    "\n",
    "\n",
    "def align_and_resample(seq1, seq2):\n",
    "    min_len = min(len(seq1), len(seq2))\n",
    "    seq1_resampled = resample(seq1, min_len)\n",
    "    seq2_resampled = resample(seq2, min_len)\n",
    "    return seq1_resampled, seq2_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c8b3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_video(url, output_path=\"video.mp4\"):\n",
    "    try:\n",
    "        ydl_opts = {\n",
    "            'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
    "            'outtmpl': output_path,\n",
    "            'merge_output_format': 'mp4',\n",
    "            'quiet': False,\n",
    "        }\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        print(f\"[INFO] Downloaded video to: {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to download {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862587ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SELECTED_INDICES = [11, 13, 15, 23, 25, 27]  \n",
    "    OUTPUT_DIR = \"outputs\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    video1_url = \"https://www.youtube.com/watch?v=V0UDCppaxEw\"\n",
    "    video2_url = \"https://www.youtube.com/watch?v=zC_F23Rxu-A\"\n",
    "\n",
    "    video1_path = \"video1.mp4\"\n",
    "    video2_path = \"video2.mp4\"\n",
    "    output_csv1 = os.path.join(r\"../data\", \"video1_keypoints.csv\")\n",
    "    output_csv2 = os.path.join(r\"../data\", \"video2_keypoints.csv\")\n",
    "\n",
    "    if not os.path.exists(video1_path):\n",
    "        download_youtube_video(video1_url, video1_path)\n",
    "    if not os.path.exists(video2_path):\n",
    "        download_youtube_video(video2_url, video2_path)\n",
    "\n",
    "    extract_keypoints_from_video(video1_path, output_csv1, debug_dir=\"debug_frames/video1\")\n",
    "    extract_keypoints_from_video(video2_path, output_csv2, start_sec=21, end_sec=31, debug_dir=\"debug_frames/video2\")\n",
    "\n",
    "    print(\"[INFO] Preprocessing keypoints...\")\n",
    "    seq1 = preprocess_keypoints(output_csv1, SELECTED_INDICES)\n",
    "    seq2 = preprocess_keypoints(output_csv2, SELECTED_INDICES)\n",
    "\n",
    "    min_len = min(len(seq1), len(seq2))\n",
    "    seq1 = resample(seq1, min_len)\n",
    "    seq2 = resample(seq2, min_len)\n",
    "\n",
    "    dtw_distance, dtw_path = fastdtw(seq1, seq2, dist=euclidean)\n",
    "    print(f\"DTW Distance Score: {round(dtw_distance, 2)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee99702",
   "metadata": {},
   "source": [
    "# DAY 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84222be1",
   "metadata": {},
   "source": [
    "## 1.Time-Series Variation Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d471d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_time_series_variation(seq1, seq2, dtw_path):\n",
    "    variations = []\n",
    "    for i, j in dtw_path:\n",
    "        diff = np.linalg.norm(seq1[i] - seq2[j])\n",
    "        variations.append(diff)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(variations, color='orange', linewidth=2)\n",
    "    plt.title(\"Time-Series Pose Variation Over Aligned Frames\")\n",
    "    plt.xlabel(\"Alignment Step\")\n",
    "    plt.ylabel(\"Euclidean Distance\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"outputs/time_series_variation.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac443678",
   "metadata": {},
   "source": [
    "## 2.DTW Cost Cost Matrix Heatmap with Alignment Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c6f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alignment_heatmap_with_values(seq1, seq2, dtw_path, output_path=\"outputs/heatmap_with_values.png\"):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from scipy.spatial.distance import cdist\n",
    "\n",
    "    cost_matrix = cdist(seq1, seq2, metric='euclidean')\n",
    "\n",
    "    plt.figure(figsize=(9, 7))\n",
    "    ax = sns.heatmap(cost_matrix, cmap=\"magma\", cbar=True, xticklabels=30, yticklabels=30)\n",
    "    ax.set_title(\"DTW Cost Matrix with Alignment Path\")\n",
    "    path_x = [j for i, j in dtw_path]\n",
    "    path_y = [i for i, j in dtw_path]\n",
    "    plt.plot(path_x, path_y, color='lime', linewidth=2, alpha=0.8)\n",
    "    plt.xlabel(\"Video 2 Frame Index\")\n",
    "    plt.ylabel(\"Video 1 Frame Index\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb906c7",
   "metadata": {},
   "source": [
    "## 3. DTW Alignment path(Scatter plot/ Line Trace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e577736f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_alignment_path_scatter(dtw_path, output_path=\"outputs/dtw_alignment_path_scatter.png\"):\n",
    "\n",
    "    v1_indices, v2_indices = zip(*dtw_path)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(v1_indices, v2_indices, color=\"red\", linewidth=2)\n",
    "    plt.title(\"DTW Alignment Path (Frame Matching)\")\n",
    "    plt.xlabel(\"Video 1 Frame Index\")\n",
    "    plt.ylabel(\"Video 2 Frame Index\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102d6e0c",
   "metadata": {},
   "source": [
    "## 4. Frame by Frame Match Trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c191e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_frame_match_trace(dtw_path, output_path=\"outputs/frame_match_trace.png\"):\n",
    "    v1, v2 = zip(*dtw_path)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.scatter(range(len(v1)), v1, s=10, label=\"Video 1\", color='blue', alpha=0.6)\n",
    "    plt.scatter(range(len(v2)), v2, s=10, label=\"Video 2\", color='orange', alpha=0.6)\n",
    "    plt.title(\"Matched Frame Indices Along DTW Path\")\n",
    "    plt.xlabel(\"Alignment Step\")\n",
    "    plt.ylabel(\"Frame Index\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35592e7e",
   "metadata": {},
   "source": [
    "## OpenAI Content Genration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd97b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import base64\n",
    "import os\n",
    "\n",
    "client = openai.OpenAI(api_key=\"sk-proj-.......\")  \n",
    "\n",
    "def encode_image_to_base64(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "def generate_gpt_conclusion_from_dtw(dtw_score, output_dir=\"outputs\"):\n",
    "    images = {\n",
    "        \"variation_plot\": os.path.join(output_dir, \"time_series_variation.png\"),\n",
    "        \"heatmap\": os.path.join(output_dir, \"heatmap_with_values.png\"),\n",
    "        \"alignment_scatter\": os.path.join(output_dir, \"dtw_alignment_scatter.png\"),\n",
    "        \"frame_trace\": os.path.join(output_dir, \"frame_match_trace.png\"),\n",
    "    }\n",
    "\n",
    "    attachments = []\n",
    "    for name, path in images.items():\n",
    "        if os.path.exists(path):\n",
    "            img_data = encode_image_to_base64(path)\n",
    "            attachments.append({\n",
    "                \"type\": \"image_url\",\n",
    "                \"image_url\": {\n",
    "                    \"url\": f\"data:image/png;base64,{img_data}\"\n",
    "                }\n",
    "            })\n",
    "\n",
    "    system_prompt = (\n",
    "        \"You are an expert in time-series pose alignment using computer vision. \"\n",
    "        f\"The user has computed DTW alignment between two yoga pose sequences with a DTW score of {dtw_score}. \"\n",
    "        \"The user has shared the following plots:\\n\"\n",
    "        \"- Time-series variation plot\\n\"\n",
    "        \"- DTW cost matrix heatmap with alignment path\\n\"\n",
    "        \"- DTW alignment scatter plot\\n\"\n",
    "        \"- Frame match trace plot\\n\\n\"\n",
    "        \"Analyze and summarize:\\n\"\n",
    "        \"- Whether the sequences are well-aligned\\n\"\n",
    "        \"- What the DTW path tells us\\n\"\n",
    "        \"- Any notable variations or mismatches\"\n",
    "    )\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4-turbo\",  \n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": attachments}\n",
    "        ],\n",
    "        max_tokens=500\n",
    "    )\n",
    "\n",
    "    print(\"\\n GPT-4-Vision Analysis:\\n\")\n",
    "    print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebe9b4",
   "metadata": {},
   "source": [
    "# Main Pipeline for Running Day 2 diliverables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95868e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_youtube_video(url, output_path=\"video.mp4\"):\n",
    "    try:\n",
    "        ydl_opts = {\n",
    "            'format': 'bestvideo[ext=mp4]+bestaudio[ext=m4a]/mp4',\n",
    "            'outtmpl': output_path,\n",
    "            'merge_output_format': 'mp4',\n",
    "            'quiet': False,\n",
    "        }\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            ydl.download([url])\n",
    "        print(f\"[INFO] Downloaded video to: {output_path}\")\n",
    "        return output_path\n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Failed to download {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d433d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    SELECTED_INDICES = [11, 13, 15, 23, 25, 27]  \n",
    "    OUTPUT_DIR = \"outputs\"\n",
    "    os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "    video1_url = \"https://www.youtube.com/watch?v=V0UDCppaxEw\"\n",
    "    video2_url = \"https://www.youtube.com/watch?v=zC_F23Rxu-A\"\n",
    "\n",
    "    video1_path = \"video1.mp4\"\n",
    "    video2_path = \"video2.mp4\"\n",
    "    output_csv1 = os.path.join(r\"../data\", \"video1_keypoints.csv\")\n",
    "    output_csv2 = os.path.join(r\"../data\", \"video2_keypoints.csv\")\n",
    "\n",
    "    if not os.path.exists(video1_path):\n",
    "        download_youtube_video(video1_url, video1_path)\n",
    "    if not os.path.exists(video2_path):\n",
    "        download_youtube_video(video2_url, video2_path)\n",
    "\n",
    "    extract_keypoints_from_video(video1_path, output_csv1, debug_dir=\"debug_frames/video1\")\n",
    "    extract_keypoints_from_video(video2_path, output_csv2, start_sec=21, end_sec=31, debug_dir=\"debug_frames/video2\")\n",
    "\n",
    "    print(\"[INFO] Preprocessing keypoints...\")\n",
    "    seq1 = preprocess_keypoints(output_csv1, SELECTED_INDICES)\n",
    "    seq2 = preprocess_keypoints(output_csv2, SELECTED_INDICES)\n",
    "\n",
    "    min_len = min(len(seq1), len(seq2))\n",
    "    seq1 = resample(seq1, min_len)\n",
    "    seq2 = resample(seq2, min_len)\n",
    "\n",
    "    dtw_distance, dtw_path = fastdtw(seq1, seq2, dist=euclidean)\n",
    "    print(f\"DTW Distance Score: {round(dtw_distance, 2)}\")\n",
    "\n",
    "\n",
    "    plot_time_series_variation(seq1, seq2, dtw_path)\n",
    "    plot_alignment_heatmap_with_values(seq1, seq2, dtw_path)\n",
    "    plot_alignment_path_scatter(dtw_path)\n",
    "    plot_frame_match_trace(dtw_path)\n",
    "\n",
    "    generate_gpt_conclusion_from_dtw(dtw_score=dtw_distance, output_dir=\"outputs\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e065ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
